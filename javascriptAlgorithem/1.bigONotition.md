# Big o notation:

- the need of Big o notation ?
determine which solotion is the best. 

a way of saying about code
- Great
-pretty good
-only Ok
-Ehhh
-Awful


what it is?

- it is how the runtime of an algorithm grows as the input grow. 


simplify it?

Difine time complexity and space complexity?

Evaluate time complexity and space?

descript what a logarithm is?



f(n) could be linear (f(n)=n)   

f = function 
f(n) n is input of the function 
=n is the output 



Example:

function addTo(n){
    return n * (n + 1) / 3 
}


is always 3 operations => o(1)

function addTo(n){
    let total = 0 
    for(let i = 0; i < n; i++){
    total += i
    }
    return total
}

is o(n)

 
 Example:

 function printn(n){
    for(let i = 0; i<n; i++){
        for(let j = 0 ; j<n; j++){
            console.log(i,j)
        }
    }
}

it is o(n^2) = o(n*n)



# rule for big o expressions:

 constants don't matter


o(2n) = o(n)

o(500)  = o(1)

o(13n^2)  = o(n^2)

1. Arithmetic operation are constant,
2. Variables assignmnet is constant.
3. accession elements in an array or object is constant
4. in loop the complexity is the length of the loop times the complexity of whatever happens inside of the loop. 

Example:

function logAtLest5(n){
    for(let i = 0; i<= Math.max(5,n); i++){
        console.log(i)
    }
}

the big o is = o(n)

as the n grows the number of operation grows


the order of complexty:

o(1)
o(log n)
o(n)
o(nlog n)
o(n^2)

# Space Complexity:

how much additional memory do we need to allocate in order to run the code. 

Rules:

1. Most primitives (boolean, numbers, undefined, null) are constant space

2. strings require O(n) space (where n is the string length)

3. Reference types are generally O(n) where n is the length or the number of keys


# Logarithms:

log is the inverse of exponint 

log2(8)=3    => 2 of what power equal 8 = 2^3 = 8

# objects:

insertation: O(1)
removal:  O(1)
searching: O(n)
Access: O(1)


